{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"},"colab":{"name":"TF CNN B cats vs dogs (실습)","provenance":[{"file_id":"1jT81Yclu6AJiH1gMeGly4-BaHacSpXpt","timestamp":1607993450557},{"file_id":"17Eh3w2gVDXbxsOrkcU8gfXIRanXtyOya","timestamp":1596216960669}],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"vY-Ca0dhGTAk"},"source":["# Category 3 - Cats vs Dogs 분류\n","\n","* Convolution Neural network 활용한 분류 모델 (Classification)\n","* tensorflow-datasets 를 활용한 데이터 전처리"]},{"cell_type":"markdown","metadata":{"id":"ww0hxcaSGb0m"},"source":["## 확인"]},{"cell_type":"markdown","metadata":{"id":"FI6oK1X-GdJJ"},"source":["1. GPU 옵션 켜져 있는지 확인할 것!!! (수정 - 노트설정 - 하드웨어설정 (GPU))"]},{"cell_type":"markdown","metadata":{"id":"1yoe-K38GQ4b"},"source":["## 순서"]},{"cell_type":"markdown","metadata":{"id":"Bc6iTV8DGPop"},"source":["1. **import**: 필요한 모듈 import\n","2. **전처리**: 학습에 필요한 데이터 전처리를 수행합니다.\n","3. **모델링(model)**: 모델을 정의합니다.\n","4. **컴파일(compile)**: 모델을 생성합니다.\n","5. **학습 (fit)**: 모델을 학습시킵니다."]},{"cell_type":"markdown","metadata":{"id":"msi1agesayxW"},"source":["## 문제"]},{"cell_type":"markdown","metadata":{"id":"Bqqzpm1P8dd9"},"source":["Computer Vision with CNNs\n","<br>\n","<br>For this exercise you will build a cats v dogs classifier\n","<br>using the Cats v Dogs dataset from TFDS.\n","<br>Be sure to use the final layer as shown \n","<br>    **(Dense, 2 neurons, softmax activation)**\n","<br>\n","<br>The testing infrastructre will **resize all images to 224x224**\n","<br>with **3 bytes of color depth**. Make sure your input layer trains\n","<br>images to that specification, or the tests will fail.\n","<br>\n","<br>Make sure your output layer is exactly as specified here, or the \n","<br>tests will fail.\n","\n","----------------------------------------\n","<br>이 연습에서는 cats v dogs 분류기를 만들 것입니다.\n","TFDS의 Cats v Dogs 데이터 세트 사용.\n","<br> 그림과 같이 최종 레이어를 사용하십시오\n","<br> **(Dense, 뉴런 2 개, activation='softmax')**\n","<br>\n","<br> 테스트 인프라는 **모든 이미지의 크기를 224x224로 조정합니다(컬러사진)**. 입력 레이어를 확인하십시오"]},{"cell_type":"code","metadata":{"id":"VXJfrSfG8dd5","executionInfo":{"status":"ok","timestamp":1608016163058,"user_tz":-540,"elapsed":2467,"user":{"displayName":"최종찬","photoUrl":"","userId":"12659814370838060539"}}},"source":["import tensorflow_datasets as tfds\n","import tensorflow as tf\n","\n","from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.callbacks import ModelCheckpoint\n"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zIXfMfFq8dd9"},"source":["## Load Dataset"]},{"cell_type":"markdown","metadata":{"id":"Kg0sXFW2nil7"},"source":["**tensorflow-datasets**를 활용합니다."]},{"cell_type":"markdown","metadata":{"id":"YTjsZFWGn117"},"source":["* [Cats vs Dogs 데이터셋 문서 보기](https://www.tensorflow.org/datasets/catalog/cats_vs_dogs?hl=ko)\n","\n","* [tensorflow-datasets 다루기](https://www.tensorflow.org/datasets/splits?hl=ko)"]},{"cell_type":"markdown","metadata":{"id":"hTCJ8FxgogB_"},"source":["**시험에서 주어지는 데이터셋 로드 형태**\n","\n","* 예전 방식이므로 아래처러 주어지는 코드를 과감히 삭제 후, 아래 제공되는 방식으로 변경합니다."]},{"cell_type":"code","metadata":{"id":"v70IGh4o8dd-","executionInfo":{"status":"ok","timestamp":1608017095483,"user_tz":-540,"elapsed":766,"user":{"displayName":"최종찬","photoUrl":"","userId":"12659814370838060539"}}},"source":["dataset_name = 'cats_vs_dogs'\n","train_dataset = tfds.load(name=dataset_name, split='train')"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"e1VLqKMO8deA","executionInfo":{"status":"ok","timestamp":1608017098333,"user_tz":-540,"elapsed":704,"user":{"displayName":"최종찬","photoUrl":"","userId":"12659814370838060539"}}},"source":["\n","dataset_name = 'cats_vs_dogs'\n","\n","#처음 80%의 데이터만 사용\n","train_dataset = tfds.load(name=dataset_name, split='train[:80%]')\n","\n","#최근 20%의 데이터만 사용\n","valid_dataset = tfds.load(name=dataset_name, split='train[80%:]')"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"739L8AKh-OZG"},"source":["시험에서 요구하는 **전처리 요구 조건**은 다음과 같습니다.\n","\n","1. 이미지 정규화 (Normalization)\n","2. 이미지 사이즈 맞추기: (224 X 224) \n","3. image(x), label(y)를 분할"]},{"cell_type":"markdown","metadata":{"id":"H7fLV4E6_8uD"},"source":["**[실습코드]**"]},{"cell_type":"code","metadata":{"id":"fV1LU9W1-Swt","executionInfo":{"status":"ok","timestamp":1608017203625,"user_tz":-540,"elapsed":706,"user":{"displayName":"최종찬","photoUrl":"","userId":"12659814370838060539"}}},"source":["def preprocess(data):\n","  #x, y데이터를 정의합니다\n","  x = data['image']\n","  y = data['label']\n","  #image 정규화 normalization\n","  x = tf.cast(x, tf.float32)/255.0\n","  #사이즈를 (224,224)로 변환.\n","  x=tf.image.resize(x, size=(224,224))\n","\n","  #x,y 데이터를 return\n","  return x,y\n","  "],"execution_count":18,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cPQ9hOrnpHKj"},"source":["만든 전처리 함수(preprocessing)를 **dataset에 mapping**하고, **batch_size도 지정**합니다."]},{"cell_type":"code","metadata":{"id":"Wq-NyPMI_oZM","executionInfo":{"status":"ok","timestamp":1608017204828,"user_tz":-540,"elapsed":918,"user":{"displayName":"최종찬","photoUrl":"","userId":"12659814370838060539"}}},"source":["batch_size=32"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"JRM0LRxt-Sru","executionInfo":{"status":"ok","timestamp":1608017205108,"user_tz":-540,"elapsed":885,"user":{"displayName":"최종찬","photoUrl":"","userId":"12659814370838060539"}}},"source":["train_data = train_dataset.map(preprocess).batch(batch_size)\n","valid_data = valid_dataset.map(preprocess).batch(batch_size)"],"execution_count":20,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uvvarzxw8ded"},"source":["## 모델 정의 (Sequential)"]},{"cell_type":"markdown","metadata":{"id":"azRvYVbQnim5"},"source":["이제 Modeling을 할 차례입니다.\n","\n","`Sequential` 모델 안에서 층을 깊게 쌓아 올려 주면 됩니다.\n","\n","1. `input_shape`는 Iris 꽃 데이터셋의 X의 feature 갯수가 4개 이므로 **(4, )**로 지정합니다.\n","2. 깊은 출력층과 더 많은 Layer를 쌓습니다.\n","3. Dense Layer에 `activation='relu'`를 적용합니다.\n","4. 분류(Classification)의 마지막 층의 출력 숫자는 분류하고자 하는 클래스 갯수와 **같아야** 합니다.\n"]},{"cell_type":"code","metadata":{"id":"rpWdaUGX8dee","executionInfo":{"status":"ok","timestamp":1608017464261,"user_tz":-540,"elapsed":832,"user":{"displayName":"최종찬","photoUrl":"","userId":"12659814370838060539"}}},"source":["model = Sequential([\n","    Conv2D(64, (3, 3), input_shape=(224, 224, 3), activation='relu'),\n","    MaxPooling2D(2, 2),\n","    Conv2D(64, (3, 3), activation='relu'),\n","    MaxPooling2D(2, 2),\n","    Conv2D(128, (3, 3), activation='relu'),\n","    MaxPooling2D(2, 2),\n","    Conv2D(128, (3, 3), activation='relu'),\n","    MaxPooling2D(2, 2),\n","    Conv2D(256, (3, 3), activation='relu'),\n","    MaxPooling2D(2, 2),\n","    Flatten(),\n","    Dropout(0.5),\n","    Dense(512, activation='relu'),\n","    Dense(128, activation='relu'),\n","    Dense(2, activation='softmax'),\n","])"],"execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"id":"iQRWnG9A8def","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608017464261,"user_tz":-540,"elapsed":472,"user":{"displayName":"최종찬","photoUrl":"","userId":"12659814370838060539"}},"outputId":"321ddbb3-581f-4e9d-f129-bd4c0f752fc2"},"source":["model.summary()"],"execution_count":27,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d (Conv2D)              (None, 222, 222, 64)      1792      \n","_________________________________________________________________\n","max_pooling2d (MaxPooling2D) (None, 111, 111, 64)      0         \n","_________________________________________________________________\n","conv2d_1 (Conv2D)            (None, 109, 109, 64)      36928     \n","_________________________________________________________________\n","max_pooling2d_1 (MaxPooling2 (None, 54, 54, 64)        0         \n","_________________________________________________________________\n","conv2d_2 (Conv2D)            (None, 52, 52, 128)       73856     \n","_________________________________________________________________\n","max_pooling2d_2 (MaxPooling2 (None, 26, 26, 128)       0         \n","_________________________________________________________________\n","conv2d_3 (Conv2D)            (None, 24, 24, 128)       147584    \n","_________________________________________________________________\n","max_pooling2d_3 (MaxPooling2 (None, 12, 12, 128)       0         \n","_________________________________________________________________\n","conv2d_4 (Conv2D)            (None, 10, 10, 256)       295168    \n","_________________________________________________________________\n","max_pooling2d_4 (MaxPooling2 (None, 5, 5, 256)         0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 6400)              0         \n","_________________________________________________________________\n","dropout (Dropout)            (None, 6400)              0         \n","_________________________________________________________________\n","dense (Dense)                (None, 512)               3277312   \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 128)               65664     \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 2)                 258       \n","=================================================================\n","Total params: 3,898,562\n","Trainable params: 3,898,562\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"wnmQV-fDnim8"},"source":["## 컴파일 (compile)"]},{"cell_type":"markdown","metadata":{"id":"pHQ1abHXK8e9"},"source":["1. `optimizer`는 가장 최적화가 잘되는 알고리즘인 'adam'을 사용합니다.\n","2. `loss`설정\n","  * 출력층 activation이 `sigmoid` 인 경우: `binary_crossentropy`\n","  * 출력층 activation이 `softmax` 인 경우: \n","    * 원핫인코딩(O): `categorical_crossentropy`\n","    * 원핫인코딩(X): `sparse_categorical_crossentropy`)\n","3. `metrics`를 'acc' 혹은 'accuracy'로 지정하면, 학습시 정확도를 모니터링 할 수 있습니다."]},{"cell_type":"markdown","metadata":{"id":"WNurLvnisN-t"},"source":["전처리 단계에서 **one-hot encoding** 을 해주었습니다. 따라서, `categorical_crossentropy`를 지정해주면 됩니다."]},{"cell_type":"markdown","metadata":{"id":"eXGMljJQhmp_"},"source":["model.compile()"]},{"cell_type":"code","metadata":{"id":"QCLw6RMZnim-","executionInfo":{"status":"ok","timestamp":1608017581462,"user_tz":-540,"elapsed":720,"user":{"displayName":"최종찬","photoUrl":"","userId":"12659814370838060539"}}},"source":["model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['acc'])"],"execution_count":28,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NyLUPgGCninB"},"source":["## ModelCheckpoint: 체크포인트 생성"]},{"cell_type":"markdown","metadata":{"id":"46Oi04ZMLtEB"},"source":["`val_loss` 기준으로 epoch 마다 최적의 모델을 저장하기 위하여, ModelCheckpoint를 만듭니다.\n","* `checkpoint_path`는 모델이 저장될 파일 명을 설정합니다.\n","* `ModelCheckpoint`을 선언하고, 적절한 옵션 값을 지정합니다."]},{"cell_type":"code","metadata":{"id":"qJwGq3PoninB","executionInfo":{"status":"ok","timestamp":1608017672343,"user_tz":-540,"elapsed":664,"user":{"displayName":"최종찬","photoUrl":"","userId":"12659814370838060539"}}},"source":["checkpoint_path = 'my_checkpoint.ckpt'\n","checkpoint = ModelCheckpoint(filepath=checkpoint_path, \n","                             save_weights_only=True,\n","                             save_best_only=True,\n","                             monitor='val_loss',\n","                             verbose=1)"],"execution_count":29,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"v3mjb5EAninE"},"source":["## 학습 (fit)"]},{"cell_type":"markdown","metadata":{"id":"3-X6hK_DMYZH"},"source":["1. `validation_data`를 반드시 지정합니다.\n","2. `epochs`을 적절하게 지정합니다.\n","3. `callbacks`에 바로 위에서 만든 checkpoint를 지정합니다."]},{"cell_type":"code","metadata":{"id":"2uHXDA_vninF","colab":{"base_uri":"https://localhost:8080/"},"outputId":"16212475-1f94-4f0d-c84c-4e6c1d6d4983"},"source":["model.fit(train_data,\n","          validation_data=(valid_data),\n","          epochs=20,\n","          callbacks=[checkpoint],\n","          )"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/20\n","582/582 [==============================] - ETA: 0s - loss: 0.6940 - acc: 0.5091\n","Epoch 00001: val_loss improved from inf to 0.69360, saving model to my_checkpoint.ckpt\n","582/582 [==============================] - 50s 87ms/step - loss: 0.6940 - acc: 0.5091 - val_loss: 0.6936 - val_acc: 0.4901\n","Epoch 2/20\n","136/582 [======>.......................] - ETA: 32s - loss: 0.6932 - acc: 0.5108"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"wwnduSgRiBw8"},"source":["## 학습 완료 후 Load Weights (ModelCheckpoint)"]},{"cell_type":"markdown","metadata":{"id":"kLqb_6XrMvdq"},"source":["학습이 완료된 후에는 반드시 `load_weights`를 해주어야 합니다.\n","\n","그렇지 않으면, 열심히 ModelCheckpoint를 만든 의미가 없습니다."]},{"cell_type":"code","metadata":{"id":"4jO1ucZ9ninH"},"source":["# checkpoint 를 저장한 파일명을 입력합니다.\n","model.load_weights(checkpoint_path)"],"execution_count":null,"outputs":[]}]}